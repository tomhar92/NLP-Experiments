{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimum Edit Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimum Edit Distance is one of the simplest and most efficient way to measure how similar two strings are. One useful usage of Minimum Edit Distance is spelling correction. The minimum edit distance is defined as the minimum number of editing operations needed to transform one string into another. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a simple python library called levenshtein that calculates the Levenshtein distance. This is the minimum edit distance with the simplest weighting factor in which each of the three possible operation (insert, substitute, delete) gets a weight of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can think of finding the MED as a search task, in which we are searching for the shortest path - a seduence of edits - from one string to another. The space of all possible edits is enormous, so we can't serach naively. <b>Dynamic Programming</b> might be a good solution to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_distance (first_substring, second_substring):\n",
    "    distance = 0;\n",
    "    chars = [];\n",
    "    for f_char in first_substring:\n",
    "        if f_char not in second_substring:\n",
    "            distance += 1;\n",
    "        else:\n",
    "            chars.append(f_char);\n",
    "    for s_char in second_substring:\n",
    "        if s_char not in first_substring:\n",
    "            distance += 1;\n",
    "        else:\n",
    "            try:\n",
    "                chars.remove(s_char);\n",
    "            except:\n",
    "                distance = distance + 1;\n",
    "    return distance + len(chars);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the first string tom\n",
      "Please enter the second string dsf\n"
     ]
    }
   ],
   "source": [
    "first_string = input(\"Please enter the first string \");\n",
    "second_string = input(\"Please enter the second string \");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_length = len(first_string);\n",
    "second_length = len(second_string);\n",
    "calc_dis = [[0 for x in range(second_length+1)] for y in range(first_length+1)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_string = \"\";\n",
    "output_string = \"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,first_length+1):\n",
    "    calc_dis [i][0] = calc_dis[i-1][0]+1;\n",
    "for j in range(1,first_length+1):\n",
    "    calc_dis [0][j] = calc_dis[0][j-1]+1;\n",
    "display(calc_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,first_length+1):\n",
    "    for j in range(1,second_length+1):\n",
    "        calc_dis [i][j] = find_distance(first_string[:i], second_string[:j]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " [1, 2, 3, 4, 5, 6, 7, 6, 7, 8],\n",
       " [2, 3, 4, 5, 6, 7, 8, 7, 8, 7],\n",
       " [3, 4, 5, 6, 7, 8, 7, 6, 7, 6],\n",
       " [4, 3, 4, 5, 6, 7, 6, 5, 6, 5],\n",
       " [5, 4, 5, 6, 7, 8, 7, 6, 7, 6],\n",
       " [6, 5, 6, 7, 8, 9, 8, 7, 8, 7],\n",
       " [7, 6, 7, 8, 9, 10, 9, 8, 9, 8],\n",
       " [8, 7, 8, 9, 10, 11, 10, 9, 8, 7],\n",
       " [9, 8, 9, 10, 11, 12, 11, 10, 9, 8]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(calc_dis);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Levenshtein Distance between intention and execution is: 8\n"
     ]
    }
   ],
   "source": [
    "print(\"The Levenshtein Distance between \"+first_string+\" and \"+second_string+\" is: \"+str(calc_dis[second_length][first_length]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Spelling Correction\n",
    "\n",
    "Now we might be able to use our code for some simple spelling correction. If we'd have a dictionary of words from multiple Wikipedia entries, we might be able to identify naively the word that our user intended to write. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_contents(number_of_wiki_pages):\n",
    "  page_contents = [];\n",
    "  while len(page_contents) < number_of_wiki_pages:\n",
    "    page_title = wikipedia.random(pages = 1);\n",
    "    try:  \n",
    "      text_content = wikipedia.WikipediaPage(title=page_title).content;\n",
    "    except wikipedia.exceptions.DisambiguationError as e:\n",
    "      try:\n",
    "        page_title = e.options[0];\n",
    "        text_content = wikipedia.WikipediaPage(title=page_title).content;\n",
    "      except wikipedia.exceptions.WikipediaException as e:\n",
    "        continue;\n",
    "    print(\"Page Number \"+str(len(page_contents) + 1)+\" is: \"+page_title);\n",
    "    page_contents.append(text_content);\n",
    "  return page_contents;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_from_content(page_contents):\n",
    "  word_tokens = [];\n",
    "  for content in page_contents:\n",
    "      words = content.split(\" \");  \n",
    "      for word in words:\n",
    "        new_word = \"\"\n",
    "        for char in re.findall(\"[a-zA-Z]\", word):\n",
    "          if char.isupper():\n",
    "            new_word = new_word + char.lower();\n",
    "          else:\n",
    "            new_word = new_word + char; \n",
    "        if new_word not in word_tokens and len(new_word) > 0:\n",
    "          word_tokens.append(new_word);\n",
    "  return word_tokens;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Number 1 is: Nikosthenes\n",
      "Page Number 2 is: Paul Blackwell\n",
      "Page Number 3 is: Adegramotide\n",
      "Page Number 4 is: Windom, Kansas\n",
      "Page Number 5 is: Sülze (Bergen)\n",
      "Page Number 6 is: Junior Eurovision Song Contest 2012\n",
      "Page Number 7 is: Welsh calendar\n",
      "Page Number 8 is: 1964 Hama riot\n",
      "Page Number 9 is: Caroline Green\n",
      "Page Number 10 is: Kirchheim (Neckar) station\n",
      "Page Number 11 is: Augnablik Kópavogur\n",
      "Page Number 12 is: José Aponte Hernández\n",
      "Page Number 13 is: Emigsville, Pennsylvania\n",
      "Page Number 14 is: Barren Grounds Nature Reserve\n",
      "Page Number 15 is: There There (novel)\n",
      "Page Number 16 is: Bazilio Olara-Okello\n",
      "Page Number 17 is: Jeeves and the Impending Doom\n",
      "Page Number 18 is: Chris Smith (pitcher, born 1981)\n",
      "Page Number 19 is: Lee Min-ho (actor)\n",
      "Page Number 20 is: Munster Schools Rugby Senior Cup\n",
      "Page Number 21 is: 60 Serpentis\n",
      "Page Number 22 is: HaDugmaniyot (season 2)\n",
      "Page Number 23 is: Juan Bautista Garcia\n",
      "Page Number 24 is: Goudi\n",
      "Page Number 25 is: Perthes-lès-Brienne\n",
      "Page Number 26 is: Precious and the Boo Hag\n",
      "Page Number 27 is: List of festivals in Ottawa\n",
      "Page Number 28 is: Zervodexios\n",
      "Page Number 29 is: Gogana ossicolor\n",
      "Page Number 30 is: Alvin Williams\n",
      "Page Number 31 is: List of Czech animated films\n",
      "Page Number 32 is: Treason Act 1817\n",
      "Page Number 33 is: Touch & Go (2003 film)\n",
      "Page Number 34 is: Fərəcan\n",
      "Page Number 35 is: Thomas J. Galvin\n",
      "Page Number 36 is: Jānis Dūklavs\n",
      "Page Number 37 is: List of airports in Mexico\n",
      "Page Number 38 is: Sahos Union\n",
      "Page Number 39 is: Petits As\n",
      "Page Number 40 is: Holley Medal\n",
      "Page Number 41 is: Pearly, Virginia\n",
      "Page Number 42 is: Rudolf Stahl\n",
      "Page Number 43 is: Kamaljit Singh Paul\n",
      "Page Number 44 is: Tol Tol, Victoria\n",
      "Page Number 45 is: Athletics at the 1996 Summer Olympics – Men's 800 metres\n",
      "Page Number 46 is: The Punisher (2004 series)\n",
      "Page Number 47 is: Eclipse parrotfish\n",
      "Page Number 48 is: 1949 NCAA Track and Field Championships\n",
      "Page Number 49 is: Agnes Tyrrell\n",
      "Page Number 50 is: List of science fiction horror films\n",
      "Page Number 51 is: Alison Phillips\n",
      "Page Number 52 is: Soner Aydoğdu\n",
      "Page Number 53 is: Saint John Airport\n",
      "Page Number 54 is: Ed Miliband\n",
      "Page Number 55 is: 1997 WTA Tour Championships – Doubles\n",
      "Page Number 56 is: Peramelemorphia\n",
      "Page Number 57 is: Carlos Espínola (footballer, born 1995)\n",
      "Page Number 58 is: Templeman, Newfoundland and Labrador\n",
      "Page Number 59 is: National Anthem of the Altai Republic\n",
      "Page Number 60 is: Joe Scott (American football)\n",
      "Page Number 61 is: Chin Haw\n",
      "Page Number 62 is: Wells Gray Park Cave discovery\n",
      "Page Number 63 is: Valsonectria\n",
      "Page Number 64 is: Miskito language\n",
      "Page Number 65 is: Nowdeh, Kowsar\n",
      "Page Number 66 is: Iron River, Michigan\n",
      "Page Number 67 is: Charge of the Black Lancers\n",
      "Page Number 68 is: Håkon Randal\n",
      "Page Number 69 is: Yogi Bear and the Three Stooges Meet the Mad, Mad, Mad Dr. No-No\n",
      "Page Number 70 is: Stan Bolovan\n",
      "Page Number 71 is: Toby Driver\n",
      "Page Number 72 is: List of Spriggan characters\n",
      "Page Number 73 is: William Bigge\n",
      "Page Number 74 is: Bina Magar\n",
      "Page Number 75 is: Gerd Rasp\n",
      "Page Number 76 is: Małe Rudy\n",
      "Page Number 77 is: Axel Axelsson (handballer)\n",
      "Page Number 78 is: Virginia Berasategui\n",
      "Page Number 79 is: Jack Schaeffer\n",
      "Page Number 80 is: List of 1969 motorsport champions\n",
      "Page Number 81 is: Vanniyampatti\n",
      "Page Number 82 is: 1975–76 National Hurling League\n",
      "Page Number 83 is: Oromo migrations\n",
      "Page Number 84 is: Nile monitor\n",
      "Page Number 85 is: Gina Lynn\n",
      "Page Number 86 is: Alvin Francis Lindsay\n",
      "Page Number 87 is: Tove of the Obotrites\n",
      "Page Number 88 is: Suraxanı, Agsu\n",
      "Page Number 89 is: Norcanair\n",
      "Page Number 90 is: 2018–19 GFA Premier League\n",
      "Page Number 91 is: Sandersleben (Anh) station\n",
      "Page Number 92 is: Victoria Mines, Nova Scotia\n",
      "Page Number 93 is: Ionuț Rus\n",
      "Page Number 94 is: 2020 RFL Championship\n",
      "Page Number 95 is: General Confederation of Mauritanian Workers\n",
      "Page Number 96 is: The Ideal Gnome Expedition\n",
      "Page Number 97 is: Sascha Nensel\n",
      "Page Number 98 is: Steel City Clown Brigade\n",
      "Page Number 99 is: Heathfield (surname)\n",
      "Page Number 100 is: Toronto Choral Society\n"
     ]
    }
   ],
   "source": [
    "number_of_wiki_pages = 100;\n",
    "page_contents = get_page_contents(number_of_wiki_pages);\n",
    "word_tokens = get_words_from_content(page_contents);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please search for a word monkey\n"
     ]
    }
   ],
   "source": [
    "word_from_user = input(\"Please search for a word \");\n",
    "distances = {};\n",
    "for word in word_tokens:\n",
    "    distances[word] = find_distance(word_from_user,word);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your top suggestions for monkey are: \n",
      "money\n",
      "koreanmy\n",
      "monk\n",
      "one\n",
      "economy\n",
      "enemy\n"
     ]
    }
   ],
   "source": [
    "print(\"Your top suggestions for \"+word_from_user+\" are: \")\n",
    "index = 0;\n",
    "for w in sorted(distances, key=distances.get, reverse=False):\n",
    "    if index <= 5:\n",
    "        print(w);\n",
    "        index += 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvements\n",
    "\n",
    "Results are looking mediocre at the moment. We might use some heuristics to improve results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_heuristics(word_one, word_two):\n",
    "    addition = 0;\n",
    "    \n",
    "    for i in range(1,min(len(word_one),len(word_two))):\n",
    "        if word_one[i] != word_two[i]:\n",
    "            addition += 1;\n",
    "    \n",
    "    return addition    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please search for a word monkey\n"
     ]
    }
   ],
   "source": [
    "word_from_user = input(\"Please search for a word \");\n",
    "distances = {};\n",
    "for word in word_tokens:\n",
    "    distances[word] = find_distance(word_from_user,word) + add_heuristics(word_from_user,word);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your top suggestions for monkey are: \n",
      "monk\n",
      "money\n",
      "mon\n",
      "no\n",
      "ken\n",
      "moe\n"
     ]
    }
   ],
   "source": [
    "print(\"Your top suggestions for \"+word_from_user+\" are: \")\n",
    "index = 0;\n",
    "for w in sorted(distances, key=distances.get, reverse=False):\n",
    "    if index <= 5:\n",
    "        print(w);\n",
    "        index += 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
