# NLP Experiments

## Word Tokenizer

I have created my own Byte Pair Encoding tokenizer using python, according to Dan Yurafsky's book.

## Min Edit Distance

I have implemented from scratch a minimum edit distance finder, and used it to create my own naive spelling checker, comparing strings from users to existing word taken from random Wikipedia entries.

## Wikipedia Tagger

I have used python to scrape random pages from Wikipedia and tag entities in them using Flair library. I have tried to use this project as a baseline for writing trivia questions out of Wikipedia entries.
